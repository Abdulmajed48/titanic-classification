{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOaCtYoHjV7dH1Yqjsqq6pH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abdulmajed48/titanic-classification/blob/main/titanic-classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ju4Jzqcc_VUx",
        "outputId": "55f1d9df-9d48-42c4-8fcf-233cb9339337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-052f0d9cb6a8>:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Age'].fillna(data['Age'].median(), inplace=True)#Median is chosen over mean because the distribution of ages might be skewed\n",
            "<ipython-input-5-052f0d9cb6a8>:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)#categorical variable, and replacing missing values with the most common category is a simple and effective approach.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.82\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.85       105\n",
            "           1       0.81      0.74      0.77        74\n",
            "\n",
            "    accuracy                           0.82       179\n",
            "   macro avg       0.82      0.81      0.81       179\n",
            "weighted avg       0.82      0.82      0.82       179\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "data = pd.read_csv(url)\n",
        "# Step 2: Data preprocessing\n",
        "\n",
        "# Step 2.1 : Drop unnecessary columns\n",
        "# the inplace=True parameter means that the operation will be performed directly on the original DataFrame\n",
        "#Without inplace=True: A new DataFrame is created with the specified columns dropped\n",
        "columns_to_drop = ['PassengerId', 'Name', 'Ticket', 'Cabin']\n",
        "data.drop(columns=columns_to_drop, inplace=True)\n",
        "\n",
        "# Step 2.2 : fill missing values\n",
        "# print(data.isnull().sum()) # check which colmun has a null values\n",
        "data['Age'].fillna(data['Age'].median(), inplace=True)#Median is chosen over mean because the distribution of ages might be skewed\n",
        "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)#categorical variable, and replacing missing values with the most common category is a simple and effective approach.\n",
        "\n",
        "# 2.3:Encode categorical variables\n",
        "encoder = LabelEncoder()\n",
        "data['Sex'] = encoder.fit_transform(data['Sex'])\n",
        "data['Embarked'] = encoder.fit_transform(data['Embarked'])\n",
        "\n",
        "# 2.4:Separate features and target\n",
        "# Separating them ensures clarity and avoids accidentally using the target as a predictor, which would lead to data leakage.\n",
        "X = data.drop('Survived', axis=1) #axis 1 Refers to columns, axis 0 refers to rows(default)\n",
        "y = data['Survived']\n",
        "\n",
        "# 2.5: Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 2.6: Standardize the features\n",
        "# The scaler computes the mean and standard deviation of each feature in the training data and uses these values to standardize the data.\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)#fit_transform: Combines the fit and transform steps for efficiency when working with the training data.\n",
        "X_test = scaler.transform(X_test) # Apply the same scaling to X_test without recomputing statistics.\n",
        "\n",
        "\n",
        "# Step 3: Train the model\n",
        "# why random forest\n",
        "# 1- It handles both categorical and numerical data.\n",
        "# 2-It is robust to overfitting, especially when you have many trees.\n",
        "# 3-Unlike linear models, Random Forests can capture complex relationships between features.\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 5: Evaluate the model\n",
        "# accuracy = Number of Correct Predictions / Total Number of Predictions\n",
        "# report Provides a comprehensive summary of model performance including:\n",
        "# Precision = Measures how many of the predicted positives were actually correct\n",
        "# recall = Measures how many actual positives the model correctly identified.\n",
        "# F-1 Score = A harmonic mean of precision and recall, balancing both.\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"Classification Report:\\n\", report)\n"
      ]
    }
  ]
}